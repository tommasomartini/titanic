{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format the data provided by Kaggle.\n",
    "\n",
    "import pandas as pd\n",
    "import dataset as ds\n",
    "import preprocessing as pp\n",
    "\n",
    "X_dataset, y_dataset = ds.load_training_set()\n",
    "X_testset = ds.load_test_set()\n",
    "\n",
    "df = pd.merge(X_dataset.reset_index(), X_testset.reset_index(), how='outer').set_index(ds.ID_COLUMN_NAME)\n",
    "\n",
    "df = pp.manual_fixes(df)\n",
    "df = pp.format_name(df)\n",
    "df = pp.add_ticket_number_column(df)\n",
    "df = df.reset_index()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Ticket == '17582']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format the extra data we crawled.\n",
    "import data.integration.merge as merge\n",
    "\n",
    "edf = merge.import_extra_data()\n",
    "edf = merge.apply_post_processing(edf)\n",
    "edf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key: Kaggle PassengerId, value: extra data PassengerId\n",
    "matches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave behind the invalid ticket numbers from the Kaggle data.\n",
    "df1 = df.loc[df['TicketNumber'] > 0]\n",
    "ticket_nrs_1 = set(df1.TicketNumber.unique())\n",
    "print('{}/{} rows, {} unique tickets'.format(len(df1), len(df), len(ticket_nrs_1)))\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are passengers with ticket number \"LINE\". Let's try to match them manually.\n",
    "valid_ticket_ids = set(df1.PassengerId.values)\n",
    "line_ticket_ids = set(df.PassengerId.values) - valid_ticket_ids\n",
    "line_ticket_df = df.loc[df.PassengerId.isin(line_ticket_ids)]\n",
    "\n",
    "# Apparently Andrew John Shannon used the name Lionel Leonard for unknown reasons.\n",
    "# See: https://www.encyclopedia-titanica.org/titanic-victim/lionel-leonard.html\n",
    "matches[180] = 1223\n",
    "matches[272] = 2148\n",
    "matches[303] = 690\n",
    "matches[598] = 688\n",
    "\n",
    "line_ticket_df.merge(edf, how='left', left_on='UnmarriedLastName', right_on='LastName')[['PassengerId_x', 'UnmarriedFirstName', 'FirstName_y', 'UnmarriedLastName', 'LastName_y', 'PassengerId_y', 'UrlId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave behind the invalid ticket numbers from the extra data.\n",
    "df2 = edf.loc[edf['TicketNumber'] > 0]\n",
    "ticket_nrs_2 = set(df2.TicketNumber.unique())\n",
    "print('{}/{} rows, {} unique tickets'.format(len(df2), len(edf), len(ticket_nrs_2)))\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the overlap between these two?\n",
    "common_ticket_nrs = ticket_nrs_1 & ticket_nrs_2\n",
    "print('{} common tickets on ({}, {})'.format(len(common_ticket_nrs), len(ticket_nrs_1), len(ticket_nrs_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the ticket numbers assigned to a single passenger in both dataframes: on these we can operate a 1-to-1 merge.\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "single_passenger_ticket_nrs = []\n",
    "for ticket_nr in tqdm(common_ticket_nrs, leave=False, disable=False):\n",
    "    sub_df1 = df1.loc[df1.TicketNumber == ticket_nr]\n",
    "    sub_df2 = df2.loc[df2.TicketNumber == ticket_nr]\n",
    "    \n",
    "    len1, len2 = len(sub_df1), len(sub_df2)\n",
    "    if len1 == 1 and len1 == len2:\n",
    "        single_passenger_ticket_nrs.append(ticket_nr)\n",
    "        id1 = sub_df1.iloc[0]['PassengerId']\n",
    "        id2 = sub_df2.iloc[0]['PassengerId']\n",
    "        matches[id1] = id2\n",
    "\n",
    "multiple_passengers_ticket_nrs = common_ticket_nrs - set(single_passenger_ticket_nrs)\n",
    "\n",
    "print('{}/{} ticket numbers assigned to a single passenger in both data frames'.format(len(single_passenger_ticket_nrs), len(common_ticket_nrs)))\n",
    "print('{}/{} passengers matched'.format(len(matches), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_match_first_names(df):\n",
    "    df = df.set_index('PassengerId')\n",
    "    \n",
    "    # These matches proposals are auto-generated.\n",
    "#     df.loc[600, 'UnmarriedFirstName'] = 'lucy' # cosmo\n",
    "    df.loc[541, 'UnmarriedFirstName'] = 'catherine' # harriet\n",
    "    df.loc[639, 'UnmarriedFirstName'] = 'maija' # maria\n",
    "    df.loc[280, 'UnmarriedFirstName'] = 'rhoda' # rosa\n",
    "    df.loc[499, 'UnmarriedFirstName'] = 'bess' # bessie\n",
    "    df.loc[1007, 'UnmarriedFirstName'] = 'dimitrios' # demetrios\n",
    "    df.loc[1019, 'UnmarriedFirstName'] = 'alice' # alicia\n",
    "    df.loc[242, 'UnmarriedFirstName'] = 'catherine' # katherine\n",
    "    df.loc[53, 'UnmarriedFirstName'] = 'myra' # myna\n",
    "#     df.loc[333, 'UnmarriedFirstName'] = 'margaret' # george\n",
    "#     df.loc[17, 'UnmarriedFirstName'] = 'francis' # eugene\n",
    "    df.loc[276, 'UnmarriedFirstName'] = 'cornelia' # kornelia\n",
    "    df.loc[1241, 'UnmarriedFirstName'] = 'ellen' # nellie\n",
    "#     df.loc[792, 'UnmarriedFirstName'] = 'william' # alfred\n",
    "    df.loc[1095, 'UnmarriedFirstName'] = 'winnifred' # winifred\n",
    "#     df.loc[490, 'UnmarriedFirstName'] = 'neville' # eden\n",
    "    df.loc[1230, 'UnmarriedFirstName'] = 'albert' # herbert\n",
    "    df.loc[270, 'UnmarriedFirstName'] = 'nellie' # amelia\n",
    "    df.loc[110, 'UnmarriedFirstName'] = 'bridget' # bertha\n",
    "#     df.loc[832, 'UnmarriedFirstName'] = 'sibley' # george\n",
    "#     df.loc[521, 'UnmarriedFirstName'] = 'mary' # anne\n",
    "    df.loc[437, 'UnmarriedFirstName'] = 'dollina' # doolina\n",
    "    \n",
    "    # These matches proposals are manually written.\n",
    "    df.loc[66, 'UnmarriedFirstName'] = 'jirjis' # jirjis\n",
    "    df.loc[710, 'UnmarriedFirstName'] = 'halim' # william\n",
    "    df.loc[1117, 'UnmarriedFirstName'] = 'aminah' # omine\n",
    "    \n",
    "    df.loc[449, 'UnmarriedFirstName'] = 'mariya' # marie\n",
    "    df.loc[470, 'UnmarriedFirstName'] = 'hilanah' # helene\n",
    "    df.loc[645, 'UnmarriedFirstName'] = 'uwjiniya' # eugenie\n",
    "    df.loc[859, 'UnmarriedFirstName'] = 'latifah' # latifa\n",
    "    \n",
    "    df.loc[208, 'UnmarriedFirstName'] = 'nasif' # nassef\n",
    "    df.loc[732, 'UnmarriedFirstName'] = 'husayn' # houssein\n",
    "    \n",
    "    df.loc[259, 'UnmarriedFirstName'] = 'annie' # anna\n",
    "\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode\n",
    "\n",
    "num_exact_matches = 0\n",
    "\n",
    "displayed = 0\n",
    "max_display = 10\n",
    "\n",
    "# Format the first names as much as possible, as we are going to try to use those to match passengers.\n",
    "df1.UnmarriedFirstName = df1.UnmarriedFirstName.apply(unidecode).str.split(expand=True)[0].str.lower()\n",
    "df2.FirstName = df2.FirstName.apply(unidecode).str.split(expand=True)[0].str.lower()\n",
    "\n",
    "# Manually fix some first names so that the Kaggle data matches my extra data.\n",
    "df1 = manually_match_first_names(df1)\n",
    "\n",
    "for ticket_nr in tqdm(multiple_passengers_ticket_nrs, disable=False):\n",
    "    sub_df1 = df1.loc[df1.TicketNumber == ticket_nr]\n",
    "    sub_df2 = df2.loc[df2.TicketNumber == ticket_nr]\n",
    "    \n",
    "    len1, len2 = len(sub_df1), len(sub_df2)\n",
    "    if len1 == len2:\n",
    "        # Same amount of passengers: there is a chance for a 1-to-1 mapping.\n",
    "\n",
    "        # Try to merge on first name.\n",
    "        merge_on_name_df = sub_df1.merge(sub_df2, how='outer', left_on=['UnmarriedFirstName'], right_on=['FirstName'])\n",
    "        if len(merge_on_name_df) == len1:\n",
    "            # All the passengers related to this ticket successfully matched!\n",
    "            num_exact_matches += 1\n",
    "            ids1 = merge_on_name_df['PassengerId_x'].tolist()\n",
    "            ids2 = merge_on_name_df['PassengerId_y'].tolist()\n",
    "            matches.update(dict(zip(ids1, ids2)))\n",
    "            continue\n",
    "        \n",
    "        # Merging on first names is still ambiguous: use the title.\n",
    "        merge_on_title_df = sub_df1.merge(sub_df2, how='outer', on='Title')\n",
    "        if len(merge_on_title_df) == len1:\n",
    "            # All the passengers related to this ticket successfully matched!\n",
    "            num_exact_matches += 1\n",
    "            ids1 = merge_on_title_df['PassengerId_x'].tolist()\n",
    "            ids2 = merge_on_title_df['PassengerId_y'].tolist()\n",
    "            matches.update(dict(zip(ids1, ids2)))\n",
    "            continue\n",
    "        \n",
    "        # First name and titles are still ambiguous. Try to use only the first letters of the first name. -> worked only in 1 case\n",
    "        \n",
    "        # Not all the passenger related to this ticket could be matched. Some probably remained unmatched and others were\n",
    "        # matched multple times. If a 1-on-1 match occurred, the PassengerId should be repeated only once.\n",
    "        unique_ids_df = merge_on_name_df.dropna(axis='index', subset=['PassengerId_x', 'PassengerId_y'], how='any')\n",
    "        unique_ids_df = unique_ids_df.drop_duplicates('PassengerId_x', keep=False)\n",
    "        unique_ids_df = unique_ids_df.drop_duplicates('PassengerId_y', keep=False)\n",
    "        \n",
    "        assert len(unique_ids_df) == len(unique_ids_df.PassengerId_x.unique())\n",
    "        assert len(unique_ids_df) == len(unique_ids_df.PassengerId_y.unique())\n",
    "        \n",
    "        ids1 = unique_ids_df['PassengerId_x'].tolist()\n",
    "        ids2 = unique_ids_df['PassengerId_y'].tolist()\n",
    "        # print(unique_ids_df[['PassengerId_x', 'UnmarriedFirstName', 'FirstName_y', 'PassengerId_y']])\n",
    "        matches.update(dict(zip(ids1, ids2)))\n",
    "        \n",
    "        # Check which passengers remain un-matched.\n",
    "        unmatched_1 = merge_on_name_df.loc[merge_on_name_df.FirstName_y.isna()]\n",
    "        unmatched_2 = merge_on_name_df.loc[merge_on_name_df.UnmarriedFirstName.isna()]\n",
    "        \n",
    "#         if len(unmatched_1) == 1 and len(unmatched_2) == 1:\n",
    "#             passenger_id = unmatched_1.PassengerId.values[0]\n",
    "#             kaggle_name = unmatched_1.UnmarriedFirstName.values[0]\n",
    "#             extra_name = unmatched_2.FirstName_y.values[0]\n",
    "#             print(\"df.loc[{}, 'UnmarriedFirstName'] = '{}' # {}\".format(int(passenger_id), extra_name, kaggle_name))\n",
    "        \n",
    "#         if len(unmatched_1) > 0 or len(unmatched_2) > 0:\n",
    "#             print('============================')\n",
    "#             print(unmatched_2[['PassengerId', 'UnmarriedFirstName', 'FirstName_y']])\n",
    "#             print(unmatched_1[['PassengerId', 'UnmarriedFirstName', 'FirstName_y']])\n",
    "\n",
    "print('{}/{} successful ticket matches'.format(num_exact_matches, len(multiple_passengers_ticket_nrs)))\n",
    "print('{} ticket numbers left'.format(len(multiple_passengers_ticket_nrs) - num_exact_matches))\n",
    "print('{}/{} passengers matched ({} left)'.format(len(matches), len(df), len(df) - len(matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to manually match the missing passengers.\n",
    "\n",
    "matches[17] = 1125\n",
    "matches[75] = 1556\n",
    "matches[170] = 810\n",
    "matches[194] = 1964\n",
    "matches[306] = 1512\n",
    "matches[312] = 2061\n",
    "matches[319] = 2185\n",
    "matches[490] = 1640\n",
    "matches[521] = 2004\n",
    "matches[551] = 2134\n",
    "matches[684] = 515\n",
    "matches[691] = 1673\n",
    "matches[699] = 1337\n",
    "matches[731] = 1509\n",
    "matches[832] = 2040\n",
    "matches[946] = 845\n",
    "matches[1015] = 248\n",
    "matches[792] = 485\n",
    "matches[573] = 1711\n",
    "matches[1031] = 513\n",
    "matches[1044] = 1300\n",
    "matches[1066] = 59\n",
    "matches[1080] = 1192\n",
    "matches[1198] = 30\n",
    "matches[1204] = 1182\n",
    "matches[1271] = 61\n",
    "matches[1252] = 1187\n",
    "matches[39] = 1384\n",
    "matches[334] = 1386\n",
    "matches[1037] = 1385\n",
    "matches[19] = 1387\n",
    "matches[149] = 963\n",
    "matches[738] = 1875\n",
    "matches[780] = 2043\n",
    "matches[782] = 1675\n",
    "matches[916] = 2058\n",
    "matches[857] = 2186\n",
    "matches[600] = 1692\n",
    "matches[557] = 1690\n",
    "matches[333] = 524\n",
    "matches[888] = 1748\n",
    "\n",
    "# Double check that the mathces are 1-on-1\n",
    "num_matches = len(matches)\n",
    "num_unique_values = len(set(matches.values()))\n",
    "assert num_matches == num_unique_values\n",
    "\n",
    "unmatched_ids1 = set(df.PassengerId.values) - set(matches.keys())\n",
    "unmatched_ids2 = set(edf.PassengerId.values) - set(matches.values())\n",
    "unmatched_passengers_df1 = df.loc[df.PassengerId.isin(unmatched_ids1)]\n",
    "unmatched_passengers_df2 = edf.loc[edf.PassengerId.isin(unmatched_ids2)]\n",
    "\n",
    "print('{}/{} passengers matched ({} left)'.format(len(matches), len(df), len(df) - len(matches)))\n",
    "\n",
    "unmatched_passengers_df1.merge(unmatched_passengers_df2, how='left', left_on='UnmarriedLastName', right_on='LastName')[['PassengerId_x', 'UnmarriedFirstName', 'FirstName_y', 'UnmarriedLastName', 'LastName_y', 'PassengerId_y', 'TicketNumber_x', 'TicketNumber_y', 'Age_x', 'Age_y', 'UrlId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "jsonizable_matches = {\n",
    "    int(k): int(v)\n",
    "    for k, v in matches.items()\n",
    "}\n",
    "\n",
    "matches_filepath = os.path.join(os.environ['HOME'], 'kaggle/titanic/data/integration', 'matches.json')\n",
    "with open(matches_filepath, 'w') as f:\n",
    "    json.dump(jsonizable_matches, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
